# Assistant, Interrupted

You’re in the flow. The assistant is helping. And then you realize—halfway through—it’s not quite doing what you hoped. So you jump in and correct it.

That’s not failure. That’s *how this is supposed to work*.

## The human-in-the-loop isn’t a fallback. It’s the whole point.

When people imagine “AI assistance,” they often picture smooth automation: you type a task, the assistant nails it, and you’re free to focus on higher things. But real collaboration with LLMs is messier—and better for it.

Interruptions, redirections, partial completions, clarifications—these aren’t bugs. They’re signals that you, the human, are shaping the work.

## Don’t apologize. Iterate.

A lot of users feel sheepish when they change direction midstream. “Sorry, actually make it a table,” or “Wait, can you try a more casual tone?” These corrections are powerful. They tell the assistant more about what matters.

And unlike with people, you won’t hurt its feelings or waste its time.

## Good tools wait for feedback

A well-designed AI system should make it easy for you to steer. That means:

- Surfacing what it’s thinking or trying to do
- Making intermediate output visible
- Letting you stop, rewind, or revise

If your assistant doesn’t handle interruption well, it’s not your fault. It’s a design flaw.

## Start with scaffolding

One technique: break up tasks into steps and review after each. For example:

1. First, generate the headings for this guide.
2. Next, write a short paragraph under each.
3. Then, revise with a more playful tone.

This lets you interrupt naturally—because it builds interruption in.

## You're not interrupting. You're collaborating.

AI tools are only useful when they’re *used*. If you’re actively steering, correcting, shaping, and editing—you’re not derailing the process.

You’re driving it.