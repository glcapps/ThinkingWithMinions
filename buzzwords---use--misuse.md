## Buzzwords: Use & Misuse

As language-model tooling has spread into business and technical discussions, its vocabulary has followed. Some terms are precise. Others are used loosely, imprecisely, or as placeholders for understanding. In this article, weâ€™ll clear the fog around the most common terms youâ€™ve likely heard in boardrooms, brainstorms, and pitches. This article clarifies common terms by separating definition from misuse.

---

### ğŸ§  Training  
**What it *means*:** The original, expensive process of creating a model. Billions of words. Massive infrastructure. It is the process by which a modelâ€™s parameters are learned from large datasets.

**How itâ€™s *misused*:** â€œWe trained ChatGPT to write our reports.â€  
No, you didnâ€™t. You *used* ChatGPT. You may have *guided* it. But unless you're OpenAI, you're not doing training.

**Common confusion:** People think every interaction â€œtrainsâ€ the model. It doesnâ€™t. That's called prompting â€” and the model forgets it as soon as you close the tab.

---

### ğŸ”§ Fine-Tuning  
**What it *means*:** Taking a pre-trained model and adjusting it slightly to specialize it. Like teaching a fluent speaker technical jargon for your industry.

**How itâ€™s *misused*:** â€œLetâ€™s fine-tune it with some emails.â€  
Fine-tuning requires specialized infrastructure and expertise and is not the same as providing examples at runtime.

**Common confusion:** Fine-tuning is *not* copy-pasting your company wiki into the prompt box. Thatâ€™s a different kind of enhancement â€” and usually not necessary.

---

### ğŸ¯ Prompt Engineering  
**What it *means*:** Designing precise instructions that help the model do what you want â€” especially when the stakes or complexity are high.

**How itâ€™s *misused*:** â€œYou just need the right prompt and itâ€™ll solve anything.â€  
Prompts matter, but theyâ€™re not magic incantations. A vague prompt plus a buzzword doesnâ€™t equal insight.

**Common confusion:** Itâ€™s not about syntax tricks â€” itâ€™s about delegation. It is closer to specifying requirements than issuing commands.

---

### ğŸ¤¯ Hallucination  
**What it *means*:** When the model confidently makes things up â€” inventing names, dates, quotes, or just fabricating answers.

**How itâ€™s *misused*:** â€œThe AI lied to us!â€  
No, it hallucinated. The model generates plausible output without verifying correctness against an external source.

**Common confusion:** People expect models to be like search engines. Theyâ€™re not. Theyâ€™re text predictors with no grounding unless you give it to them.

---

### ğŸ“š Context  
**What it *means*:** The total amount of information the model can â€œhold in mindâ€ during a session â€” the information made available to the model during a single interaction.

**How itâ€™s *misused*:** â€œThis model has lots of context, so it knows everything.â€  
Nope. Context is *temporary.* Once the chat ends or the limit is hit, itâ€™s gone.

**Common confusion:** Many assume context is infinite â€” but every word you add eats into the limit. Managing context is a critical skill in LLM use.

---

### ğŸ”¡ Token  
**What it *means*:** A chunk of text â€” not quite a word, not quite a syllable. Models read and respond in tokens.

**How itâ€™s *misused*:** â€œIt can read my 100-page report.â€  
Not if that report is more tokens than the modelâ€™s limit. Know your modelâ€™s budget.

**Common confusion:** Tokens represent processing units. Larger inputs consume more capacity.

---

### ğŸ“¦ RAG (Retrieval-Augmented Generation)  
**What it *means*:** A technique that feeds external knowledge into the model in real time by retrieving and supplying external material as part of the generation process.

**How itâ€™s *misused*:** â€œWe do RAG, so accuracy is solved.â€  
RAG is helpful â€” but not a silver bullet. Poor documents in, poor answers out.

**Common confusion:** RAG is not search. Itâ€™s a system architecture. Just having access to files doesnâ€™t mean the answers improve.

---

### ğŸ¤– Smart  
**What it *means*:** There is no single technical definition. The term is often used as a proxy for capability without specifying which capability is being discussed.

**How itâ€™s *misused*:** â€œThis is the smartest AI yet.â€  
â€œSmartâ€ is vague. Are we talking about creativity? Logic? Memory? Cost-efficiency? Be specific.

**Common confusion:** Bigger doesnâ€™t mean better. Sometimes the â€œsmarterâ€ model gives worse answers â€” or just more expensive ones.

---

## ğŸš« Buzzwords Youâ€™re Probably Misusing

- **Training:** Youâ€™re *prompting*, not training.
- **Fine-tuning:** Unless you hired a lab, youâ€™re not.
- **Hallucination:** Itâ€™s not lying. Itâ€™s guessing.
- **Token:** Think of it like text budget, not words.
- **Smart:** Specify the capability or behavior being referenced.

---

Buzzwords are not inherently harmful. Precision is what makes them useful.